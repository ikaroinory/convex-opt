\section{实验内容}

本实验将进行如下工作：

第一，介绍各种典型的优化方法。
将系统地梳理优化算法的基本分类与原理，涵盖从无需梯度信息的无导数优化方法到依赖梯度信息的有导数优化方法。
在一阶优化器部分，将重点讲解基于梯度信息的优化策略，包括最基本的梯度下降法、适用于非光滑目标函数的次梯度下降法，以及加速收敛的共轭方向法、共轭梯度法和采用迭代更新Hessian矩阵近似的变尺度法（如BFGS法）。
二阶优化器则引入目标函数的Hessian矩阵以提升收敛速度，典型方法包括Newton法与其改进形式阻尼Newton法，后者通过调整Hessian矩阵提升算法稳定性。
此外，还将介绍交替方向乘子法（ADMM）这种适用于分布式和约束优化问题的有效算法，以及Krylov子空间方法等在高维大规模问题中应用广泛的迭代式优化策略。

第二，实现上述优化方法。
利用Python编程语言实现所介绍的各类优化算法。
为了确保每种方法具有通用性和可扩展性，将使用PyTorch框架对各种优化器进行实现，继承Optimizer接口，便于后续在不同类型的目标函数上进行测试和比较。

第三，测试上述优化方法。
使用一个典型的测试函数对各优化器进行性能评估——Rosenbrock函数。
实验将对每种优化器在在相同初始点下的收敛过程进行可视化分析，并对优化器性能进行比较。
